{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maskify/maskify.github.io/blob/master/Unsupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BqNcVnrj8G4"
      },
      "source": [
        "###import commands\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from pylab import *\n",
        "from matplotlib.pyplot import *\n",
        "import imageio\n",
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjTJiM2ilZgn"
      },
      "source": [
        "###import files from Github to Kaggle -> GoogleColab "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGw7uf3_sUyD"
      },
      "source": [
        "**import files from Github to Kaggle -> GoogleColab **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPq3sK7hnISz"
      },
      "source": [
        "###install Kaggle onto Colab\n",
        "# To install Kaggle CLI:\n",
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jitUmh8FrO6s"
      },
      "source": [
        "###Choose the kaggle.json file that you downloaded\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdfWIruorTMc"
      },
      "source": [
        "###Make directory named kaggle and copy kaggle.json file there.\n",
        "! mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI0hY5wwrA0Y"
      },
      "source": [
        "#import json \n",
        "token = {\"username\":\"ninachen99\",\"key\":\"ee5999a7fab2b35a875f1490862a902e\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axbLPpkdqyoT"
      },
      "source": [
        "with open('/content/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGaS6Xht6xH4"
      },
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtPq4KGd60ib"
      },
      "source": [
        "#!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jsmo_-f7AWz"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76KU1wnr7GX2",
        "outputId": "9459f9e9-1af4-4b6a-f10d-9d15a5eedef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle datasets download -d ninachen99/maskify-data/data_with_masks -p /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading maskify-data.zip to /content\n",
            " 98% 377M/384M [00:03<00:00, 93.9MB/s]\n",
            "100% 384M/384M [00:03<00:00, 119MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TufD6KRk7yFn"
      },
      "source": [
        "!unzip \\maskify-data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJcppL8t724R"
      },
      "source": [
        "####testing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = plt.imread('/content/data_with_masks/withMask1.jpg')\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcH0YMaLYm5Z"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "DIRECTORY = \"./data_raw\"\n",
        "# Percentage of images to be used for the valid set\n",
        "percentage_test = 20;\n",
        "# Create train.txt and valid.txt\n",
        "file_train = open('train.txt', 'w')  \n",
        "file_test = open('valid.txt', 'w')\n",
        "# Populate train.txt and valid.txt\n",
        "var = \"/content/data_raw\"\n",
        "counter = 1  \n",
        "index_test = round(100 / percentage_test)  \n",
        "#for file in glob.iglob(os.path.join(current_dir, '*.jpg')):  \n",
        "for f in os.listdir(DIRECTORY):\n",
        "    if os.path.splitext(f)[1].lower() in ('.jpg', '.jpeg'):\n",
        "      if counter == index_test:\n",
        "        counter = 1\n",
        "        file_test.write(os.path.join(var,f)+\"\\n\")\n",
        "      else:\n",
        "        file_train.write(os.path.join(var,f)+\"\\n\")\n",
        "        counter = counter + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dssMcEdfZkD"
      },
      "source": [
        "**Connect the Colab notebook to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxbH1GT1ffWC"
      },
      "source": [
        "# This cell imports the drive library and mounts your Google Drive as a VM local drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UUU5oGAffTB"
      },
      "source": [
        "# List the content of your local computer folder \n",
        "!ls -la \"/content/gdrive/My Drive/CS 4641/Implementation/darknet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmXP_CvSf8bN"
      },
      "source": [
        "!sudo apt-get install tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSbEo41LgAz3"
      },
      "source": [
        "!tree /content/gdrive/My\\ Drive/CS\\ 4641/Implementation/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tRn-VX9gska"
      },
      "source": [
        "**Check CUDA release version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_9DQhmVgtvI"
      },
      "source": [
        "# This cell can be commented once you checked the current CUDA version\n",
        "# CUDA: Let's check that Nvidia CUDA is already pre-installed and which version is it. In some time from now maybe you \n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCQWsH9bj6ln"
      },
      "source": [
        "**Install cuDNN according to the current CUDA version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slSnjG2Jj9Ly"
      },
      "source": [
        "# We're unzipping the cuDNN files from your Drive folder directly to the VM CUDA folders\n",
        "!tar -xzvf gdrive/My\\ Drive/CS\\ 4641/Implementation/darknet/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "\n",
        "# Now we check the version we already installed. Can comment this line on future runs\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIMHgnVNlk8G"
      },
      "source": [
        "**Installing Darknet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMAWbsUelsnz"
      },
      "source": [
        "*Cloning and compiling Darkent. ONLY NEEDS TO BE RUN ON THE FIRST EXECUTION!!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe1OknrKlvYj"
      },
      "source": [
        "!git clone https://github.com/maskify/darknet/\n",
        "%cd darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WejFh0wGnLVI",
        "outputId": "4d1d984c-b311-40b5-8320-f02051a92ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the folder\n",
        "!ls\n",
        "\n",
        "# I have a branch where I have done the changes commented above\n",
        "!git checkout feature/google-colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3rdparty      CMakeLists.txt\t      image_yolov3.sh\t     scripts\n",
            "appveyor.yml  CMakeSettings.json      include\t\t     src\n",
            "build\t      DarknetConfig.cmake.in  json_mjpeg_streams.sh  video_v2.sh\n",
            "build.ps1     darknet.py\t      LICENSE\t\t     video_yolov3.sh\n",
            "build.sh      darknet_video.py\t      Makefile\n",
            "cfg\t      data\t\t      net_cam_v3.sh\n",
            "cmake\t      image_yolov2.sh\t      README.md\n",
            "error: pathspec 'feature/google-colab' did not match any file(s) known to git.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7xUBYMLnOiw"
      },
      "source": [
        "#Compile Darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv5rJVOCpVSW"
      },
      "source": [
        "#Copies the Darknet compiled version to Google drive\n",
        "!cp ./darknet /content/gdrive/My\\ Drive/CS\\ 4641/Implementation/darknet/bin/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZiWMDbDnrJ_"
      },
      "source": [
        "# Makes a dir for darknets and move there\n",
        "!mkdir darknets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp27wavXnssW"
      },
      "source": [
        "%cd darknets\n",
        "#!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baNVqzlOnzhY"
      },
      "source": [
        "# Copy the Darkent compiled version to the VM local drive\n",
        "!cp /content/gdrive/My\\ Drive/CS\\ 4641/Implementation/darknet/bin/darknet ./darknets -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UvJZAETn1Q1"
      },
      "source": [
        "# Set execution permissions to Darknets\n",
        "!chmod +x ./darknets/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KbHMsVKoXJK"
      },
      "source": [
        "**Runtime configuration finished!**   *Run the following cells in order to check if everything goes as expected!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh2Y70vkocl9"
      },
      "source": [
        "#download files\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImZ9NJ7CohI7"
      },
      "source": [
        "# Not necessary cell\n",
        "# Get yolov3 weights \n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trYivG-F-OVL"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxOAiP-wB_fJ"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZM-nggqpFBp"
      },
      "source": [
        "# Not necessary cell\n",
        "# Execute darknets using YOLOv3 model with pre-trained weights to detect objects on 'person.jpg'\n",
        "!./darknets/darknets/darknet detect cfg/yolov3.cfg yolov3.weights data/person.jpg -dont-show\n",
        "\n",
        "#!./darknets/darknets/darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/person.jpg\n",
        "\n",
        "# Show the result using the helper imgShow()\n",
        "\n",
        "#plt.imshow(np.real('predictions.jpg'))\n",
        "#plt.show()\n",
        "\n",
        "A = imageio.imread('predictions.jpg')\n",
        "plt.imshow(A)\n",
        "#plt.imshow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IMXdeL9hrAE",
        "outputId": "99007f5f-42e8-4e29-d074-c3368403b553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./darknet/darknets/darknets/darknet detector train \"/content/gdrive/My Drive/CS 4641/Implementation/obj.data\" \"/content/gdrive/My Drive/CS 4641/Implementation/yolov3-custom.cfg\" \"/content/gdrive/My Drive/CS 4641/Implementation/darknet53.conv.74\" -dont_show "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./darknet/darknets/darknets/darknet: Not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJEeF4Tmh4bO"
      },
      "source": [
        "./darknet detector test data/voc.data yolo-voc.cfg yolo-voc.weights -dont_show < data/train.txt > result.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPAqEnuM6au4"
      },
      "source": [
        "**PCA Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BZUCR3c9cBZ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class ImgCompression(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def svd(self, X): \n",
        "        if (len(X.shape)==2):\n",
        "            np_x = np.array(X)\n",
        "            U, S, V = np.linalg.svd(np_x)\n",
        "        else:\n",
        "            X_reshape = X.transpose(2,0,1)\n",
        "            N = X.shape[0]\n",
        "            D = X.shape[1]\n",
        "            U = []\n",
        "            S = []\n",
        "            V = []\n",
        "            for i in range(3):\n",
        "                np_x = np.array(X_reshape[i])\n",
        "                Ui, Si, Vi = np.linalg.svd(np_x)\n",
        "                U.append(Ui)\n",
        "                S.append(Si)\n",
        "                V.append(Vi)\n",
        "            U = np.array(U).transpose(1,2,0)\n",
        "            S = np.array(S).transpose(1,0)\n",
        "            V = np.array(V).transpose(1,2,0)\n",
        "        return U, S, V\n",
        "\n",
        "    def rebuild_svd(self, U, S, V, k):\n",
        "        if U.ndim == 2:\n",
        "            U = U[:, :k]\n",
        "            S = S[:k]\n",
        "            V = V[:k, :]\n",
        "\n",
        "            SV = np.matmul(np.diag(S), V)\n",
        "            Xrebuild = np.matmul(U, SV)\n",
        "        else:\n",
        "            Xrebuild = np.zeros((U.shape[0], V.shape[0], 3))\n",
        "\n",
        "            for i in range(3):\n",
        "                SV = np.matmul(np.diag(S[:k, i]), V[:k, :, i])\n",
        "                Xrebuild[:, :, i] = np.matmul(U[:, :k, i], SV)\n",
        "\n",
        "        return Xrebuild\n",
        "\n",
        "    def compression_ratio(self, X, k): \n",
        "        if (len(X.shape) == 2):\n",
        "            image_size = X.shape[1]*X.shape[0]\n",
        "            compressed_size = k*(X.shape[1]+X.shape[0]+1)\n",
        "        else:\n",
        "            image_size = X.shape[1]*X.shape[0]*3\n",
        "            compressed_size = k*(X.shape[1]+X.shape[0]+1)*3\n",
        "        return compressed_size/image_size\n",
        "\n",
        "\n",
        "    def recovered_variance_proportion(self, S, k): \n",
        "        N = S.shape[0]\n",
        "        if (len(S.shape) == 1):\n",
        "            S_k = S[:k]\n",
        "            S_k_sq = np.square(S_k)\n",
        "            sum_S_k = np.sum(S_k_sq)/N\n",
        "            S_sq = np.square(S)\n",
        "            sum_S = np.sum(S_sq)/N\n",
        "            return sum_S_k/sum_S\n",
        "        else:\n",
        "            S_t = S.transpose()\n",
        "            S_t_k = S_t[:,:k]\n",
        "            S_t_k_sq = np.square(S_t_k)\n",
        "            sum_S_k = np.sum(S_t_k_sq, axis=1)/N\n",
        "            sum_S = np.sum(np.square(S_t), axis=1)/N\n",
        "            return np.divide(sum_S_k, sum_S).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsjQr8IMCx01"
      },
      "source": [
        "#Read Image\n",
        "# Helper Function No need to modify\n",
        "# load Image\n",
        "\n",
        "from PIL import Image\n",
        "import os, os.path\n",
        "\n",
        "imgs = []\n",
        "path = \"/content/data_with_masks\"\n",
        "valid_images = [\".jpg\",\".jpeg\",\".png\",\".img\"]\n",
        "for f in os.listdir(path):\n",
        "    ext = os.path.splitext(f)[1]\n",
        "    if ext.lower() not in valid_images:\n",
        "        continue\n",
        "    imgs.append(Image.open(os.path.join(path,f)))\n",
        "\n",
        "    image = plt.imread(path +\"/\" +f)/255.\n",
        "    #plot image\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "    #implementation\n",
        "    #helper do not need to change\n",
        "    imcompression = ImgCompression()\n",
        "    U, S, V = imcompression.svd(image)\n",
        "    component_num = [1,2,5,10,20,40,80]\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 18))\n",
        "    # plot several images\n",
        "    i=0\n",
        "    for k in component_num:\n",
        "        img_rebuild = imcompression.rebuild_svd(U, S, V, k)\n",
        "        c = np.around(imcompression.compression_ratio(image, k), 4)\n",
        "        r = np.around(imcompression.recovered_variance_proportion(S, k), 3)\n",
        "        ax = fig.add_subplot(3, 3, i + 1, xticks=[], yticks=[])\n",
        "        ax.imshow(img_rebuild)\n",
        "        ax.set_title(f\"{k} Components\")\n",
        "        ax.set_xlabel(f\"Compression: {np.around(c,4)},\\nRecovered Variance:  R: {r[0]}  G: {r[1]}  B: {r[2]}\")\n",
        "        i = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toJV0YPUuj1d"
      },
      "source": [
        "**Normalize Pixel Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50fV2h5BZEfh"
      },
      "source": [
        "%mkdir data_with_masks_compressed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CJPTtfHY-QZ"
      },
      "source": [
        "# example of pixel normalization\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "# load image\n",
        "# image = Image.open('./data_raw/004f.jpeg')\n",
        "def scale_pixel(image): \n",
        "  # #Normalize\n",
        "  pixels = asarray(image)\n",
        "  mean, std = pixels.mean(), pixels.std()\n",
        "  # confirm pixel range is 0-1\n",
        "  # print('Data Type: %s' % pixels.dt\n",
        "  min = pixels.min()\n",
        "  max = pixels.max() \n",
        "  # print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
        "  # convert from integers to floats\n",
        "  pixels = pixels.astype('float32')\n",
        "  pixels = np.array((pixels - np.min(pixels)) / (np.max(pixels) - np.min(pixels)))\n",
        "  np.where(pixels < 0, 0, pixels)\n",
        "  np.where(pixels > 1, 1, pixels)\n",
        "  pixels = pixels.astype('float32')\n",
        "\n",
        "  return pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR35HilJMUYr"
      },
      "source": [
        "**Pixel normalization and Image compression**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBMmChXieQr4"
      },
      "source": [
        "import os, os.path\n",
        "import cv2\n",
        "imgs = []\n",
        "path = \"/content/data_with_masks/\"\n",
        "valid_images = [\".jpg\",\".jpeg\",\".png\",\".img\"]\n",
        "i = 1\n",
        "for f in os.listdir(path):\n",
        "    ext = os.path.splitext(f)[1]\n",
        "    if ext.lower() not in valid_images:\n",
        "        continue\n",
        "    imgs.append(Image.open(os.path.join(path,f)))\n",
        "\n",
        "    image = plt.imread(path +\"/\" +f)\n",
        "    #plot image\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    \n",
        "    #implementation\n",
        "    #helper do not need to change\n",
        "    imcompression = ImgCompression()\n",
        "    U, S, V = imcompression.svd(image)\n",
        "    component_num = [1,2,5,10,20,40,80]\n",
        "    k = 20\n",
        "    img_rebuild = imcompression.rebuild_svd(U, S, V, k)\n",
        "    img_rebuild = scale_pixel(img_rebuild)\n",
        "    # print(img_rebuild)\n",
        "    c = np.around(imcompression.compression_ratio(image, k), 4)\n",
        "    r = np.around(imcompression.recovered_variance_proportion(S, k), 3)\n",
        "\n",
        "    curr_directory = r'/content'\n",
        "    # Image directory \n",
        "    directory = r'/content/data_with_masks_compressed'\n",
        "      \n",
        "    # Change the current directory  \n",
        "    # to specified directory  \n",
        "    os.chdir(directory) \n",
        "      \n",
        "    # Filename \n",
        "    filename = 'data_with_mask-' + str(i) + '-compressed.jpg'\n",
        "      \n",
        "    # Saving the image \n",
        "    plt.imsave(filename, img_rebuild)\n",
        "    print(\"saved\")\n",
        "    i = i+1\n",
        "    del image\n",
        "    del img_rebuild"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSFLLAaXr_MQ",
        "outputId": "7ebf84c3-08cc-4609-cd8f-1d44551d10e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ..\n",
        "%mkdir data_with_masks_compressed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebXH7V6m3gZA"
      },
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/data_with_masks_compressed.zip /content/data_with_masks_compressed/\n",
        "files.download(\"/content/data_with_masks_compressed.zip\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQQ6uZzJbOHy"
      },
      "source": [
        "#print image\n",
        "plt.figure()\n",
        "plt.imshow(pixels, interpolation='none')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image, interpolation='none')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OVgOBg-9ETF"
      },
      "source": [
        "**Making Testing and Training Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9wHXbhA1oN_"
      },
      "source": [
        "import os, os.path\n",
        "import cv2\n",
        "from matplotlib.image import imread\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "imgs = []\n",
        "path = \"/content/test_data\"\n",
        "valid_images = [\".jpg\",\".jpeg\",\".png\",\".img\"]\n",
        "i = 1\n",
        "y_test = [] \n",
        "x_test = [] \n",
        "#y_test = np.zeros(319)\n",
        "#x_test = np.zeros((319,128,3))\n",
        "index = 0 \n",
        "for f in os.listdir(path):\n",
        "    ext = os.path.splitext(f)[1]\n",
        "    if ext.lower() not in valid_images:\n",
        "        continue\n",
        "\n",
        "    if f == \"^mixed\" or \"^withoutMask\":\n",
        "      imgs.append(Image.open(os.path.join(path,f)))\n",
        "\n",
        "      image = plt.imread(path +\"/\" +f)\n",
        "      #print(type(image))\n",
        "      fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "      #append zeros to y_train\n",
        "      y_test.append(0)\n",
        "      x_test.append(image)\n",
        "\n",
        "    elif f == \"^withMask\":\n",
        "      imgs.append(Image.open(os.path.join(path,f)))\n",
        "\n",
        "      image = plt.imread(path +\"/\" +f)\n",
        "      #print(type(image))\n",
        "      fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "      #append ones to y_train\n",
        "      y_test.append(1)\n",
        "      x_test.append(image)\n",
        "      #print(y_test)\n",
        "\n",
        "#print(len(x_test[0]))\n",
        "y_test = np.asarray(y_test, dtype = np.float32)\n",
        "x_test = np.asarray(x_test, dtype = np.float32)\n",
        "#print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHH7dn0u5B2m"
      },
      "source": [
        "import os, os.path\n",
        "import cv2\n",
        "from matplotlib.image import imread\n",
        "\n",
        "imgs = []\n",
        "path = \"/content/train_data\"\n",
        "valid_images = [\".jpg\",\".jpeg\",\".png\",\".img\"]\n",
        "i = 1\n",
        "y_train = [] \n",
        "x_train = [] \n",
        "for f in os.listdir(path):\n",
        "    ext = os.path.splitext(f)[1]\n",
        "    if ext.lower() not in valid_images:\n",
        "        continue\n",
        "\n",
        "    if f == \"mixed+\" or \"withoutMask+\":\n",
        "      imgs.append(Image.open(os.path.join(path,f)))\n",
        "      image = plt.imread(path +\"/\" +f,0)\n",
        "      fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "      #append zeros to y_train\n",
        "      y_train.append(0)\n",
        "      x_train.append(image)\n",
        "\n",
        "    elif f == \"withMask+\":\n",
        "      imgs.append(Image.open(os.path.join(path,f)))\n",
        "      image = plt.imread(path +\"/\" +f,0)\n",
        "      #print(type(image))\n",
        "      fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "      #append zeros to y_train\n",
        "      y_train.append(1)\n",
        "      x_train.append(image)\n",
        "y_train = np.array(y_train, dtype = np.float32)\n",
        "x_train = np.array(x_train, dtype = np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le3HvH8J5R6r"
      },
      "source": [
        "print(type(x_train))\n",
        "print(type(x_test))\n",
        "print(type(y_train))\n",
        "print(type(y_test))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oPiaUVKLgzY"
      },
      "source": [
        "**Implmenting HSV QUANTIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPL_H5W5NMfA"
      },
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def quantize_hsv(img: np.ndarray, k: int) -> np.ndarray:\n",
        "    #img = Image.open('./data_raw/004f.jpeg')\n",
        "    width, height, dim = tuple(img.shape)\n",
        "\n",
        "    hsvImg = rgb2hsv(img)\n",
        "    reshaped = np.reshape(hsvImg[:, :, 0], (-1, 1))\n",
        "\n",
        "    clustering = KMeans(n_clusters = k, random_state = 101).fit(reshaped)\n",
        "    \n",
        "    centers = clustering.cluster_centers_\n",
        "    labels = clustering.predict(reshaped)\n",
        "    \n",
        "    quantized_img = hsvImg\n",
        "    quantized_img[:, :, 0] = np.reshape(centers[labels], (hsvImg[:, :, 0].shape))\n",
        "    \n",
        "    quantized_img = (np.floor(hsv2rgb(quantized_img) * 255)).astype(np.uint8)\n",
        "    #plt.show(quantized_img)\n",
        "    return quantized_img\n",
        "\n",
        "img = imageio.imread('./data_raw/004f.jpeg')\n",
        "plt.imshow(quantize_hsv(img, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW8F3EgaW_eY"
      },
      "source": [
        "from sklearn.cluster import KMeans \n",
        "from sklearn import metrics \n",
        "from scipy.spatial.distance import cdist \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "inertias = [] \n",
        "K = range(1,10) \n",
        "#X = imageio.imread('./data_raw/004f.jpeg')\n",
        "X = imageio.imread('./data_raw/010-wuhan-coronavirus_1024.jpg')\n",
        "\n",
        "X = X[:,:,0]\n",
        "\n",
        "for k in K: \n",
        "  hsvImg = rgb2hsv(img)\n",
        "  kmeanModel = KMeans(n_clusters=k).fit(X) \n",
        "  kmeanModel.fit(X)\t \n",
        "  inertias.append(kmeanModel.inertia_)\n",
        "\n",
        "plt.plot(K, inertias, 'bx-') \n",
        "plt.xlabel('Values of K') \n",
        "plt.ylabel('Inertia') \n",
        "plt.title('The Elbow Method using Inertia') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0kUX4XZPxFi"
      },
      "source": [
        "import cv2\n",
        "imgs = []\n",
        "path = \"/content/data_with_masks_compressed/\"\n",
        "valid_images = [\".jpg\",\".jpeg\",\".png\",\".img\"]\n",
        "i = 1\n",
        "for f in os.listdir(path):\n",
        "    ext = os.path.splitext(f)[1]\n",
        "    if ext.lower() not in valid_images:\n",
        "        continue\n",
        "    imgs.append(Image.open(os.path.join(path,f)))\n",
        "\n",
        "    image = plt.imread(path +\"/\" +f)\n",
        "    #plot image\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    \n",
        "    #implementation\n",
        "    k = 20\n",
        "    quantized_img_hsv = quantize_hsv(image, k)\n",
        "\n",
        "    curr_directory = r'/content'\n",
        "    # Image directory \n",
        "    directory = r'/content/data_with_masks_compressed'\n",
        "      \n",
        "    # Change the current directory  \n",
        "    # to specified directory  \n",
        "    os.chdir(directory) \n",
        "      \n",
        "    # List files and directories   \n",
        "    # print(\"Before saving image:\")   \n",
        "    # print(os.listdir(directory))   \n",
        "      \n",
        "    # Filename \n",
        "    filename = 'data_with_mask-' + str(i) + '-compressed.jpg'\n",
        "      \n",
        "    # Using cv2.imwrite() method \n",
        "    # Saving the image \n",
        "    \n",
        "    plt.imsave(filename, img_rebuild)\n",
        "    print(\"saved\")\n",
        "\n",
        "    i = i+1\n",
        "    del image\n",
        "    del img_rebuild"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgRXIjAxRFqa"
      },
      "source": [
        "def get_hue_histograms(img: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    hist_equal = np.zeros((k,), dtype=np.int64)\n",
        "    hist_clustered = np.zeros((k,), dtype=np.int64)\n",
        "\n",
        "    hsvImg = rgb2hsv(img)\n",
        "\n",
        "    reshaped = np.reshape(hsvImg[:, :, 0], (-1, 1))\n",
        "    hist_equal = np.histogram(reshaped, bins= k)[0]\n",
        "    \n",
        "    clustering = KMeans(n_clusters = k, random_state = 101).fit(reshaped)\n",
        "    labels = clustering.predict(reshaped)\n",
        "\n",
        "    hist_clustered = np.histogram(labels, bins= k)[0]\n",
        "    \n",
        "    return hist_equal, hist_clustered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNFk6ImuUKed"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2)\n",
        "k = 20\n",
        "axs.set_title(\"Histograms K=20 Image\")\n",
        "axs[0].set_title(\"equal\")\n",
        "axs[0].bar(np.arange(k), hist_equal)\n",
        "\n",
        "axs[1].set_title(\"clustered\")\n",
        "axs[1].bar(np.arange(k), hist_clustered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71hB047GFr7w"
      },
      "source": [
        "###object detection using YOLOv3 using Ultralytics"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}